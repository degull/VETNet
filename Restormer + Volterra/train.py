# train.py
# E:\restormer+volterra\Restormer + Volterra\train.py
""" import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, ConcatDataset
from torchvision import transforms
from tqdm import tqdm
from torch.amp import autocast, GradScaler
import numpy as np
from skimage.metrics import peak_signal_noise_ratio as compute_psnr
from skimage.metrics import structural_similarity as compute_ssim

from models.restormer_volterra import RestormerVolterra
from re_dataset.rain100h_dataset import Rain100HDataset
from re_dataset.gopro_dataset import GoProDataset
from re_dataset.sidd_dataset import SIDD_Dataset

# ‚úÖ ÌïôÏäµ ÏÑ§Ï†ï
BATCH_SIZE = 2
EPOCHS = 100
LR = 2e-4
DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# ‚úÖ Í≤ΩÎ°ú ÏÑ§Ï†ï
RAIN100H_DIR = 'E:/restormer+volterra/data/rain100H/train'
GOPRO_CSV = 'E:/restormer+volterra/data/GOPRO_Large/gopro_train_pairs.csv'
SIDD_DIR = 'E:/restormer+volterra/data/SIDD'

SAVE_DIR = 'checkpoints/restormer_volterra_train_4sets'
os.makedirs(SAVE_DIR, exist_ok=True)

# ‚úÖ Progressive Learning Ïä§ÏºÄÏ§Ñ
resize_schedule = {
    0: 128,
    30: 192,
    60: 256
}

def get_transform(epoch):
    size = 256
    for key in sorted(resize_schedule.keys()):
        if epoch >= key:
            size = resize_schedule[key]
    return transforms.Compose([
        transforms.Resize((size, size)),
        transforms.ToTensor()
    ])

def main():
    model = RestormerVolterra().to(DEVICE)
    criterion = nn.MSELoss()
    optimizer = optim.Adam(model.parameters(), lr=LR)
    scaler = GradScaler(device='cuda')

    for epoch in range(EPOCHS):
        transform = get_transform(epoch)

        # ‚úÖ Îç∞Ïù¥ÌÑ∞ÏÖã Î°úÎìú
        rain100h_dataset = Rain100HDataset(root_dir=RAIN100H_DIR, transform=transform)
        gopro_dataset = GoProDataset(csv_path=GOPRO_CSV, transform=transform)
        sidd_dataset = SIDD_Dataset(root_dir=SIDD_DIR, transform=transform)

        # ‚úÖ Îç∞Ïù¥ÌÑ∞ÏÖã ÌÜµÌï©
        train_dataset = ConcatDataset([
            rain100h_dataset,
            gopro_dataset,
            sidd_dataset
        ])

        train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE,
                                  shuffle=True, num_workers=4, pin_memory=True)

        print(f"[Epoch {epoch+1}] Input resolution: {transform.transforms[0].size}, Total samples: {len(train_dataset)}")

        model.train()
        epoch_loss = 0
        total_psnr, total_ssim, count = 0.0, 0.0, 0
        loop = tqdm(train_loader, desc=f"Epoch [{epoch+1}/{EPOCHS}]", leave=False)

        for distorted, reference in loop:
            distorted, reference = distorted.to(DEVICE), reference.to(DEVICE)
            optimizer.zero_grad()

            with autocast(device_type='cuda'):
                output = model(distorted)
                loss = criterion(output, reference)

            scaler.scale(loss).backward()
            scaler.step(optimizer)
            scaler.update()

            epoch_loss += loss.item()

            # ‚úÖ PSNR / SSIM Í≥ÑÏÇ∞ (batch ÎÇ¥ Ï≤´ ÏÉòÌîå Í∏∞Ï§Ä)
            out_np = output[0].detach().cpu().numpy().transpose(1, 2, 0)
            ref_np = reference[0].detach().cpu().numpy().transpose(1, 2, 0)

            psnr = compute_psnr(ref_np, out_np, data_range=1.0)
            ssim = compute_ssim(ref_np, out_np, channel_axis=2, data_range=1.0, win_size=7)

            total_psnr += psnr
            total_ssim += ssim
            count += 1

            loop.set_postfix(loss=loss.item(), psnr=f"{psnr:.2f}", ssim=f"{ssim:.3f}")

        print(f"Epoch [{epoch+1}/{EPOCHS}] Loss: {epoch_loss / len(train_loader):.6f} | "
              f"Avg PSNR: {total_psnr / count:.2f} | Avg SSIM: {total_ssim / count:.4f}")

        # ‚úÖ Î™®Îç∏ Ï†ÄÏû•
        torch.save(model.state_dict(), os.path.join(SAVE_DIR, f"epoch_{epoch+1}.pth"))

if __name__ == '__main__':
    main()  """





# Ïù¥Ïñ¥ÏÑú ÌïôÏäµ
# train.py
# E:/MRVNet2D/Restormer + Volterra/train.py
""" 
import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, ConcatDataset
from torchvision import transforms
from tqdm import tqdm
from torch.amp import autocast, GradScaler
import numpy as np
from skimage.metrics import peak_signal_noise_ratio as compute_psnr
from skimage.metrics import structural_similarity as compute_ssim

from restormer_volterra import RestormerVolterra
from kadid_dataset import KADID10KDataset
from re_dataset.rain100h_dataset import Rain100HDataset
from re_dataset.gopro_dataset import GoProDataset
from re_dataset.sidd_dataset import SIDD_Dataset

# ‚úÖ ÏÑ§Ï†ï
BATCH_SIZE = 2
EPOCHS = 100
LR = 2e-4
DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# ‚úÖ Í≤ΩÎ°ú
KADID_CSV = 'E:/restormer+volterra/data/KADID10K/kadid10k.csv'
RAIN100H_DIR = 'E:/restormer+volterra/data/rain100H/train'
GOPRO_CSV = 'E:/restormer+volterra/data/GOPRO_Large/gopro_train_pairs.csv'
SIDD_DIR = 'E:/restormer+volterra/data/SIDD'
SAVE_DIR = 'checkpoints/restormer_volterra_train_4sets'
CHECKPOINT_PATH = os.path.join(SAVE_DIR, 'epoch_98.pth')
os.makedirs(SAVE_DIR, exist_ok=True)

# ‚úÖ Progressive Learning
resize_schedule = {
    0: 128,
    30: 192,
    60: 256
}

def get_transform(epoch):
    size = 256
    for key in sorted(resize_schedule.keys()):
        if epoch >= key:
            size = resize_schedule[key]
    return transforms.Compose([
        transforms.Resize((size, size)),
        transforms.ToTensor()
    ])

def main():
    model = RestormerVolterra().to(DEVICE)
    optimizer = optim.Adam(model.parameters(), lr=LR)
    scaler = GradScaler(device='cuda')

    resume_epoch = 0

    # ‚úÖ Ï≤¥ÌÅ¨Ìè¨Ïù∏Ìä∏Í∞Ä Ï°¥Ïû¨ÌïòÎ©¥ Ïù¥Ïñ¥ÏÑú ÌïôÏäµ
    if os.path.exists(CHECKPOINT_PATH):
        print(f"üîÅ Loading checkpoint from {CHECKPOINT_PATH}")
        checkpoint = torch.load(CHECKPOINT_PATH, map_location=DEVICE)
        model.load_state_dict(checkpoint)
        resume_epoch = 98  # ÏàòÎèô ÏÑ§Ï†ï (ÌååÏùºÎ™Ö Í∏∞Ï§Ä)

    criterion = nn.MSELoss()

    for epoch in range(resume_epoch, EPOCHS):
        transform = get_transform(epoch)

        # ‚úÖ Îç∞Ïù¥ÌÑ∞ÏÖã
        kadid_dataset = KADID10KDataset(csv_file=KADID_CSV, transform=transform)
        rain100h_dataset = Rain100HDataset(root_dir=RAIN100H_DIR, transform=transform)
        gopro_dataset = GoProDataset(csv_path=GOPRO_CSV, transform=transform)
        sidd_dataset = SIDD_Dataset(root_dir=SIDD_DIR, transform=transform)

        train_dataset = ConcatDataset([kadid_dataset, rain100h_dataset, gopro_dataset, sidd_dataset])
        train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)

        print(f"[Epoch {epoch+1}] Input resolution: {transform.transforms[0].size}, Total samples: {len(train_dataset)}")

        model.train()
        epoch_loss = 0
        total_psnr, total_ssim, count = 0.0, 0.0, 0
        loop = tqdm(train_loader, desc=f"Epoch [{epoch+1}/{EPOCHS}]", leave=False)

        for distorted, reference in loop:
            distorted, reference = distorted.to(DEVICE), reference.to(DEVICE)
            optimizer.zero_grad()

            with autocast(device_type='cuda'):
                output = model(distorted)
                loss = criterion(output, reference)

            scaler.scale(loss).backward()
            scaler.step(optimizer)
            scaler.update()

            epoch_loss += loss.item()

            # PSNR/SSIM (batch Ï≤´ ÏÉòÌîå Í∏∞Ï§Ä)
            out_np = output[0].detach().cpu().numpy().transpose(1, 2, 0)
            ref_np = reference[0].detach().cpu().numpy().transpose(1, 2, 0)

            psnr = compute_psnr(ref_np, out_np, data_range=1.0)
            ssim = compute_ssim(ref_np, out_np, channel_axis=2, data_range=1.0, win_size=7)

            total_psnr += psnr
            total_ssim += ssim
            count += 1

            loop.set_postfix(loss=loss.item(), psnr=f"{psnr:.2f}", ssim=f"{ssim:.3f}")

        print(f"Epoch [{epoch+1}/{EPOCHS}] Loss: {epoch_loss / len(train_loader):.6f} | "
              f"Avg PSNR: {total_psnr / count:.2f} | Avg SSIM: {total_ssim / count:.4f}")

        # ‚úÖ Ï†ÄÏû•
        torch.save(model.state_dict(), os.path.join(SAVE_DIR, f"epoch_{epoch+1}.pth"))

if __name__ == '__main__':
    main()
 """

# E:\restormer+volterra\Restormer + Volterra\train_reside.py
# RESIDE-6K (Haze) Îã®ÎèÖ ÌïôÏäµ + Í≤∞Í≥º ÏãúÍ∞ÅÌôî Ï†ÄÏû•
# - train/test split ÏÇ¨Ïö©
# - AMP + GradScaler
# - epochÎßàÎã§ test ÌèâÍ∑† PSNR/SSIM
# - results Ìè¥ÎçîÏóê (ÏõêÎ≥∏|Î≥µÏõê|GT) Í∞ÄÎ°úÎ°ú Î∂ôÏù∏ PNG Ï†ÄÏû•
# - PNG ÏïÑÎûòÏóê PSNR/SSIM ÌÖçÏä§Ìä∏ÎèÑ Í∞ôÏù¥ Î†åÎçîÎßÅ
""" 
import os
import sys
import time

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import transforms
from tqdm import tqdm

from torch.amp import autocast, GradScaler
import numpy as np
from skimage.metrics import peak_signal_noise_ratio as compute_psnr
from skimage.metrics import structural_similarity as compute_ssim

from PIL import Image, ImageDraw, ImageFont

# ----------------------
# Path setup (models: current dir, re_dataset: repo root)
# ----------------------
CUR_DIR = os.path.dirname(os.path.abspath(__file__))  # .../Restormer + Volterra
ROOT_DIR = os.path.dirname(CUR_DIR)                   # .../restormer+volterra
for p in [CUR_DIR, ROOT_DIR]:
    if p not in sys.path:
        sys.path.insert(0, p)

from models.restormer_volterra import RestormerVolterra
from re_dataset.reside_dataset import RESIDEDataset


# ======================
# Config
# ======================
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

RESIDE_ROOT = r"E:/restormer+volterra/data/RESIDE-6K"

SAVE_DIR = r"E:/restormer+volterra/checkpoints/restormer_volterra_reside"
os.makedirs(SAVE_DIR, exist_ok=True)

RESULTS_DIR = r"E:/restormer+volterra/results/reside_train"
os.makedirs(RESULTS_DIR, exist_ok=True)

BATCH_SIZE = 1               # hazeÎäî Ìï¥ÏÉÅÎèÑ Ïª§ÏÑú 1 Ï∂îÏ≤ú (OOM Î∞©ÏßÄ)
EPOCHS = 100
LR = 2e-4
NUM_WORKERS = 4
PIN_MEMORY = True

USE_AMP = True               # AMP ÏºúÍ∏∞
SAVE_VIS_EVERY_EPOCH = 1     # Îß§ epochÎßàÎã§ ÏãúÍ∞ÅÌôî Ï†ÄÏû• (ÏõêÌïòÎ©¥ 5,10 Îì±ÏúºÎ°ú)

# Í∞Å epochÏóêÏÑú Î™á Ïû• Ï†ÄÏû•Ìï†ÏßÄ
NUM_VIS_SAVE = 5             # testÏóêÏÑú ÏïûÏ™Ω Î™á Ïû• Ï†ÄÏû•

# Progressive resize schedule
resize_schedule = {
    0: 128,
    30: 192,
    60: 256,
}


def get_transform(epoch: int):
    size = 256
    for key in sorted(resize_schedule.keys()):
        if epoch >= key:
            size = resize_schedule[key]
    return transforms.Compose([
        transforms.Resize((size, size)),
        transforms.ToTensor(),
    ]), size


def tensor_to_hwc01(x: torch.Tensor) -> np.ndarray:
    if x.dim() == 4:
        x = x[0]
    x = x.detach().float().clamp(0, 1).cpu().numpy()
    x = np.transpose(x, (1, 2, 0))
    return x


def hwc01_to_pil(img: np.ndarray) -> Image.Image:
    img_u8 = (np.clip(img, 0, 1) * 255.0).astype(np.uint8)
    return Image.fromarray(img_u8, mode="RGB")


def render_triplet_with_text(hazy_np, restored_np, gt_np, psnr, ssim,
                             title_left="Input(Hazy)", title_mid="Restored", title_right="GT",
                             pad=12, text_h=54) -> Image.Image:

    hazy_p = hwc01_to_pil(hazy_np)
    res_p = hwc01_to_pil(restored_np)
    gt_p = hwc01_to_pil(gt_np)

    w, h = hazy_p.size
    canvas_w = w * 3 + pad * 4
    canvas_h = h + text_h + pad * 3

    canvas = Image.new("RGB", (canvas_w, canvas_h), (255, 255, 255))
    draw = ImageDraw.Draw(canvas)

    # Ìè∞Ìä∏ (ÏúàÎèÑÏö∞ Í∏∞Î≥∏ Ìè∞Ìä∏ ÏãúÎèÑ -> Ïã§Ìå®ÌïòÎ©¥ Í∏∞Î≥∏)
    try:
        font = ImageFont.truetype("arial.ttf", 18)
        font_b = ImageFont.truetype("arial.ttf", 20)
    except Exception:
        font = ImageFont.load_default()
        font_b = ImageFont.load_default()

    # ÏÉÅÎã® ÌÉÄÏù¥ÌãÄ
    y_title = pad
    draw.text((pad + (w // 2) - 40, y_title), title_left, fill=(0, 0, 0), font=font_b)
    draw.text((pad * 2 + w + (w // 2) - 35, y_title), title_mid, fill=(0, 0, 0), font=font_b)
    draw.text((pad * 3 + w * 2 + (w // 2) - 10, y_title), title_right, fill=(0, 0, 0), font=font_b)

    # Ïù¥ÎØ∏ÏßÄ Î∂ôÏù¥Í∏∞
    y_img = pad * 2 + 18
    x1 = pad
    x2 = pad * 2 + w
    x3 = pad * 3 + w * 2

    canvas.paste(hazy_p, (x1, y_img))
    canvas.paste(res_p, (x2, y_img))
    canvas.paste(gt_p, (x3, y_img))

    # ÏïÑÎûò metric ÌÖçÏä§Ìä∏
    y_text = y_img + h + pad
    metric_text = f"PSNR: {psnr:.2f} dB    SSIM: {ssim:.4f}"
    draw.text((pad, y_text), metric_text, fill=(0, 0, 0), font=font_b)

    return canvas


def evaluate_one_epoch(model, loader, criterion, epoch: int, vis_size: int,
                       save_visuals: bool = True, num_save: int = 5):

    model.eval()
    total_loss = 0.0
    total_psnr, total_ssim, count = 0.0, 0.0, 0

    saved = 0
    epoch_vis_dir = os.path.join(RESULTS_DIR, f"epoch_{epoch:03d}")
    if save_visuals:
        os.makedirs(epoch_vis_dir, exist_ok=True)

    with torch.no_grad():
        for i, (hazy, gt) in enumerate(tqdm(loader, desc="Validating", leave=False), start=1):
            hazy = hazy.to(DEVICE, non_blocking=True)
            gt = gt.to(DEVICE, non_blocking=True)

            with autocast(device_type="cuda", enabled=(USE_AMP and DEVICE.type == "cuda")):
                out = model(hazy)
                loss = criterion(out, gt)

            total_loss += float(loss.item())

            hazy_np = tensor_to_hwc01(hazy)
            out_np = tensor_to_hwc01(out)
            gt_np = tensor_to_hwc01(gt)

            psnr = compute_psnr(gt_np, out_np, data_range=1.0)
            ssim = compute_ssim(gt_np, out_np, channel_axis=2, data_range=1.0, win_size=7)

            total_psnr += psnr
            total_ssim += ssim
            count += 1

            # ÏãúÍ∞ÅÌôî Ï†ÄÏû•
            if save_visuals and saved < num_save:
                vis = render_triplet_with_text(
                    hazy_np=hazy_np,
                    restored_np=out_np,
                    gt_np=gt_np,
                    psnr=psnr,
                    ssim=ssim
                )
                out_path = os.path.join(epoch_vis_dir, f"sample_{saved+1:02d}_psnr{psnr:.2f}_ssim{ssim:.4f}.png")
                vis.save(out_path)
                saved += 1

    avg_loss = total_loss / max(len(loader), 1)
    avg_psnr = total_psnr / max(count, 1)
    avg_ssim = total_ssim / max(count, 1)
    return avg_loss, avg_psnr, avg_ssim


def main():
    torch.backends.cudnn.benchmark = True
    if DEVICE.type == "cuda":
        torch.cuda.empty_cache()

    model = RestormerVolterra().to(DEVICE)
    criterion = nn.MSELoss()
    optimizer = optim.Adam(model.parameters(), lr=LR)
    scaler = GradScaler(device="cuda")  # torch>=2.x

    for epoch in range(EPOCHS):
        transform, size = get_transform(epoch)

        # ----------------------
        # Dataset / Loader
        # ----------------------
        train_set = RESIDEDataset(root_dir=RESIDE_ROOT, split="train", transform=transform, strict=True)
        test_set  = RESIDEDataset(root_dir=RESIDE_ROOT, split="test",  transform=transform, strict=True)

        train_loader = DataLoader(
            train_set,
            batch_size=BATCH_SIZE,
            shuffle=True,
            num_workers=NUM_WORKERS,
            pin_memory=(PIN_MEMORY and DEVICE.type == "cuda"),
            drop_last=True,
        )
        test_loader = DataLoader(
            test_set,
            batch_size=1,
            shuffle=False,
            num_workers=NUM_WORKERS,
            pin_memory=(PIN_MEMORY and DEVICE.type == "cuda"),
        )

        print(f"\n[Epoch {epoch+1}/{EPOCHS}] RESIDE input: {size}x{size} | train={len(train_set)} | test={len(test_set)}")

        # ----------------------
        # Train
        # ----------------------
        model.train()
        epoch_loss = 0.0
        total_psnr, total_ssim, count = 0.0, 0.0, 0

        loop = tqdm(train_loader, desc=f"Train [{epoch+1}/{EPOCHS}]", leave=False)
        t0 = time.time()

        for step, (hazy, gt) in enumerate(loop, start=1):
            hazy = hazy.to(DEVICE, non_blocking=True)
            gt = gt.to(DEVICE, non_blocking=True)

            optimizer.zero_grad(set_to_none=True)

            with autocast(device_type="cuda", enabled=(USE_AMP and DEVICE.type == "cuda")):
                out = model(hazy)
                loss = criterion(out, gt)

            scaler.scale(loss).backward()
            scaler.step(optimizer)
            scaler.update()

            epoch_loss += float(loss.item())

            # --- metric (batch Ï≤´ ÏÉòÌîå)
            out_np = tensor_to_hwc01(out)
            gt_np = tensor_to_hwc01(gt)

            psnr = compute_psnr(gt_np, out_np, data_range=1.0)
            ssim = compute_ssim(gt_np, out_np, channel_axis=2, data_range=1.0, win_size=7)

            total_psnr += psnr
            total_ssim += ssim
            count += 1

            loop.set_postfix(loss=f"{loss.item():.4f}", psnr=f"{psnr:.2f}", ssim=f"{ssim:.3f}")

        dt = time.time() - t0
        train_loss = epoch_loss / max(len(train_loader), 1)
        train_psnr = total_psnr / max(count, 1)
        train_ssim = total_ssim / max(count, 1)

        print(f"[Train] loss={train_loss:.6f} | psnr={train_psnr:.2f} | ssim={train_ssim:.4f} | time={dt/60:.1f}m")

        # ----------------------
        # Validate (test split) + save visuals
        # ----------------------
        save_visuals = (SAVE_VIS_EVERY_EPOCH > 0) and ((epoch + 1) % SAVE_VIS_EVERY_EPOCH == 0)
        val_loss, val_psnr, val_ssim = evaluate_one_epoch(
            model=model,
            loader=test_loader,
            criterion=criterion,
            epoch=epoch + 1,
            vis_size=size,
            save_visuals=save_visuals,
            num_save=NUM_VIS_SAVE
        )
        print(f"[Test ] loss={val_loss:.6f} | psnr={val_psnr:.2f} | ssim={val_ssim:.4f}")
        if save_visuals:
            print(f"[Vis  ] Saved {NUM_VIS_SAVE} triplets to: {os.path.join(RESULTS_DIR, f'epoch_{epoch+1:03d}')}")

        # ----------------------
        # Save checkpoint (ÌååÏùºÎ™ÖÏóê metric Ìè¨Ìï®)
        # ----------------------
        ckpt_name = f"epoch_{epoch+1:03d}_ssim{val_ssim:.4f}_psnr{val_psnr:.2f}.pth"
        ckpt_path = os.path.join(SAVE_DIR, ckpt_name)
        torch.save(model.state_dict(), ckpt_path)
        print(f"[Save] {ckpt_path}")


if __name__ == "__main__":
    main()
 """

# E:\restormer+volterra\Restormer + Volterra\train_reside.py
# RESIDE-6K (Haze) Îã®ÎèÖ ÌïôÏäµ + Resume(Ïù¥Ïñ¥ÌïôÏäµ) + Í≤∞Í≥º ÏãúÍ∞ÅÌôî Ï†ÄÏû•
# - ÏßÄÏ†ï ckptÏóêÏÑú Ïù¥Ïñ¥ÏÑú ÌïôÏäµ (epoch_013... -> Îã§Ïùå epochÎ∂ÄÌÑ∞)
# - AMP + GradScaler
# - epochÎßàÎã§ test ÌèâÍ∑† PSNR/SSIM
# - results Ìè¥ÎçîÏóê (ÏõêÎ≥∏|Î≥µÏõê|GT) PNG Ï†ÄÏû• + ÏïÑÎûòÏóê PSNR/SSIM ÌÖçÏä§Ìä∏ Î†åÎçîÎßÅ

""" import os
import sys
import time
import re

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import transforms
from tqdm import tqdm

from torch.amp import autocast, GradScaler
import numpy as np
from skimage.metrics import peak_signal_noise_ratio as compute_psnr
from skimage.metrics import structural_similarity as compute_ssim

from PIL import Image, ImageDraw, ImageFont

# ----------------------
# Path setup (models: current dir, re_dataset: repo root)
# ----------------------
CUR_DIR = os.path.dirname(os.path.abspath(__file__))  # .../Restormer + Volterra
ROOT_DIR = os.path.dirname(CUR_DIR)                   # .../restormer+volterra
for p in [CUR_DIR, ROOT_DIR]:
    if p not in sys.path:
        sys.path.insert(0, p)

from models.restormer_volterra import RestormerVolterra
from re_dataset.reside_dataset import RESIDEDataset


# ======================
# Config
# ======================
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

RESIDE_ROOT = r"E:/restormer+volterra/data/RESIDE-6K"

SAVE_DIR = r"E:/restormer+volterra/checkpoints/restormer_volterra_reside"
os.makedirs(SAVE_DIR, exist_ok=True)

RESULTS_DIR = r"E:/restormer+volterra/results/reside_train"
os.makedirs(RESULTS_DIR, exist_ok=True)

# ‚úÖ Resume checkpoint (Ïó¨Í∏∞Î∂ÄÌÑ∞ Ïù¥Ïñ¥ÏÑú ÌïôÏäµ)
RESUME_CKPT = r"E:\restormer+volterra\checkpoints\restormer_volterra_reside\epoch_017_ssim0.9464_psnr27.01.pth"
RESUME = True  # FalseÎ©¥ Ï≤òÏùåÎ∂ÄÌÑ∞ ÌïôÏäµ

BATCH_SIZE = 1
EPOCHS = 100              # ÏµúÏ¢Ö Î™©Ìëú epoch
LR = 2e-4
NUM_WORKERS = 4
PIN_MEMORY = True

USE_AMP = True
SAVE_VIS_EVERY_EPOCH = 1
NUM_VIS_SAVE = 5

resize_schedule = {
    0: 128,
    30: 192,
    60: 256,
}


def parse_epoch_from_ckpt(path: str) -> int:
    name = os.path.basename(path)
    m = re.search(r"epoch_(\d+)", name)
    return int(m.group(1)) if m else 0


def get_transform(epoch: int):
    size = 256
    for key in sorted(resize_schedule.keys()):
        if epoch >= key:
            size = resize_schedule[key]
    return transforms.Compose([
        transforms.Resize((size, size)),
        transforms.ToTensor(),
    ]), size


def tensor_to_hwc01(x: torch.Tensor) -> np.ndarray:
    if x.dim() == 4:
        x = x[0]
    x = x.detach().float().clamp(0, 1).cpu().numpy()
    x = np.transpose(x, (1, 2, 0))
    return x


def hwc01_to_pil(img: np.ndarray) -> Image.Image:
    img_u8 = (np.clip(img, 0, 1) * 255.0).astype(np.uint8)
    return Image.fromarray(img_u8, mode="RGB")


def render_triplet_with_text(hazy_np, restored_np, gt_np, psnr, ssim,
                             title_left="Input(Hazy)", title_mid="Restored", title_right="GT",
                             pad=12, text_h=54) -> Image.Image:
    hazy_p = hwc01_to_pil(hazy_np)
    res_p = hwc01_to_pil(restored_np)
    gt_p = hwc01_to_pil(gt_np)

    w, h = hazy_p.size
    canvas_w = w * 3 + pad * 4
    canvas_h = h + text_h + pad * 3

    canvas = Image.new("RGB", (canvas_w, canvas_h), (255, 255, 255))
    draw = ImageDraw.Draw(canvas)

    try:
        font = ImageFont.truetype("arial.ttf", 18)
        font_b = ImageFont.truetype("arial.ttf", 20)
    except Exception:
        font = ImageFont.load_default()
        font_b = ImageFont.load_default()

    y_title = pad
    draw.text((pad + (w // 2) - 40, y_title), title_left, fill=(0, 0, 0), font=font_b)
    draw.text((pad * 2 + w + (w // 2) - 35, y_title), title_mid, fill=(0, 0, 0), font=font_b)
    draw.text((pad * 3 + w * 2 + (w // 2) - 10, y_title), title_right, fill=(0, 0, 0), font=font_b)

    y_img = pad * 2 + 18
    x1 = pad
    x2 = pad * 2 + w
    x3 = pad * 3 + w * 2

    canvas.paste(hazy_p, (x1, y_img))
    canvas.paste(res_p, (x2, y_img))
    canvas.paste(gt_p, (x3, y_img))

    y_text = y_img + h + pad
    metric_text = f"PSNR: {psnr:.2f} dB    SSIM: {ssim:.4f}"
    draw.text((pad, y_text), metric_text, fill=(0, 0, 0), font=font_b)

    return canvas


def evaluate_one_epoch(model, loader, criterion, epoch: int,
                       save_visuals: bool = True, num_save: int = 5):
    model.eval()
    total_loss = 0.0
    total_psnr, total_ssim, count = 0.0, 0.0, 0

    saved = 0
    epoch_vis_dir = os.path.join(RESULTS_DIR, f"epoch_{epoch:03d}")
    if save_visuals:
        os.makedirs(epoch_vis_dir, exist_ok=True)

    with torch.no_grad():
        for _, (hazy, gt) in enumerate(tqdm(loader, desc="Validating", leave=False), start=1):
            hazy = hazy.to(DEVICE, non_blocking=True)
            gt = gt.to(DEVICE, non_blocking=True)

            with autocast(device_type="cuda", enabled=(USE_AMP and DEVICE.type == "cuda")):
                out = model(hazy)
                loss = criterion(out, gt)

            total_loss += float(loss.item())

            hazy_np = tensor_to_hwc01(hazy)
            out_np = tensor_to_hwc01(out)
            gt_np = tensor_to_hwc01(gt)

            psnr = compute_psnr(gt_np, out_np, data_range=1.0)
            ssim = compute_ssim(gt_np, out_np, channel_axis=2, data_range=1.0, win_size=7)

            total_psnr += psnr
            total_ssim += ssim
            count += 1

            if save_visuals and saved < num_save:
                vis = render_triplet_with_text(hazy_np, out_np, gt_np, psnr, ssim)
                out_path = os.path.join(epoch_vis_dir, f"sample_{saved+1:02d}_psnr{psnr:.2f}_ssim{ssim:.4f}.png")
                vis.save(out_path)
                saved += 1

    avg_loss = total_loss / max(len(loader), 1)
    avg_psnr = total_psnr / max(count, 1)
    avg_ssim = total_ssim / max(count, 1)
    return avg_loss, avg_psnr, avg_ssim


def main():
    torch.backends.cudnn.benchmark = True
    if DEVICE.type == "cuda":
        torch.cuda.empty_cache()

    model = RestormerVolterra().to(DEVICE)
    criterion = nn.MSELoss()
    optimizer = optim.Adam(model.parameters(), lr=LR)
    scaler = GradScaler(device="cuda")

    # ----------------------
    # ‚úÖ Resume (model weights)
    # ----------------------
    start_epoch = 0  # 0-based index for loop
    if RESUME:
        if not os.path.exists(RESUME_CKPT):
            raise FileNotFoundError(f"Resume checkpoint not found: {RESUME_CKPT}")

        print(f"[Resume] Loading: {RESUME_CKPT}")
        state = torch.load(RESUME_CKPT, map_location=DEVICE)
        model.load_state_dict(state, strict=True)

        last_epoch = parse_epoch_from_ckpt(RESUME_CKPT)  # e.g., 13
        # Îã§Ïùå epochÎ∂ÄÌÑ∞ Ïù¥Ïñ¥ÏÑú (epoch 14Î∂ÄÌÑ∞)
        start_epoch = last_epoch
        print(f"[Resume] Detected last_epoch={last_epoch} -> start from epoch {start_epoch+1}")

    # ----------------------
    # Training loop
    # ----------------------
    for epoch_idx in range(start_epoch, EPOCHS):
        epoch_num = epoch_idx + 1  # human-readable 1..EPOCHS

        transform, size = get_transform(epoch_num)

        train_set = RESIDEDataset(root_dir=RESIDE_ROOT, split="train", transform=transform, strict=True)
        test_set  = RESIDEDataset(root_dir=RESIDE_ROOT, split="test",  transform=transform, strict=True)

        train_loader = DataLoader(
            train_set,
            batch_size=BATCH_SIZE,
            shuffle=True,
            num_workers=NUM_WORKERS,
            pin_memory=(PIN_MEMORY and DEVICE.type == "cuda"),
            drop_last=True,
        )
        test_loader = DataLoader(
            test_set,
            batch_size=1,
            shuffle=False,
            num_workers=NUM_WORKERS,
            pin_memory=(PIN_MEMORY and DEVICE.type == "cuda"),
        )

        print(f"\n[Epoch {epoch_num}/{EPOCHS}] RESIDE input: {size}x{size} | train={len(train_set)} | test={len(test_set)}")

        # ---- Train ----
        model.train()
        epoch_loss = 0.0
        total_psnr, total_ssim, count = 0.0, 0.0, 0

        loop = tqdm(train_loader, desc=f"Train [{epoch_num}/{EPOCHS}]", leave=False)
        t0 = time.time()

        for _, (hazy, gt) in enumerate(loop, start=1):
            hazy = hazy.to(DEVICE, non_blocking=True)
            gt = gt.to(DEVICE, non_blocking=True)

            optimizer.zero_grad(set_to_none=True)

            with autocast(device_type="cuda", enabled=(USE_AMP and DEVICE.type == "cuda")):
                out = model(hazy)
                loss = criterion(out, gt)

            scaler.scale(loss).backward()
            scaler.step(optimizer)
            scaler.update()

            epoch_loss += float(loss.item())

            out_np = tensor_to_hwc01(out)
            gt_np = tensor_to_hwc01(gt)

            psnr = compute_psnr(gt_np, out_np, data_range=1.0)
            ssim = compute_ssim(gt_np, out_np, channel_axis=2, data_range=1.0, win_size=7)

            total_psnr += psnr
            total_ssim += ssim
            count += 1

            loop.set_postfix(loss=f"{loss.item():.4f}", psnr=f"{psnr:.2f}", ssim=f"{ssim:.3f}")

        dt = time.time() - t0
        train_loss = epoch_loss / max(len(train_loader), 1)
        train_psnr = total_psnr / max(count, 1)
        train_ssim = total_ssim / max(count, 1)

        print(f"[Train] loss={train_loss:.6f} | psnr={train_psnr:.2f} | ssim={train_ssim:.4f} | time={dt/60:.1f}m")

        # ---- Validate + save visuals ----
        save_visuals = (SAVE_VIS_EVERY_EPOCH > 0) and (epoch_num % SAVE_VIS_EVERY_EPOCH == 0)
        val_loss, val_psnr, val_ssim = evaluate_one_epoch(
            model=model,
            loader=test_loader,
            criterion=criterion,
            epoch=epoch_num,
            save_visuals=save_visuals,
            num_save=NUM_VIS_SAVE
        )
        print(f"[Test ] loss={val_loss:.6f} | psnr={val_psnr:.2f} | ssim={val_ssim:.4f}")
        if save_visuals:
            print(f"[Vis  ] Saved {NUM_VIS_SAVE} triplets to: {os.path.join(RESULTS_DIR, f'epoch_{epoch_num:03d}')}")

        # ---- Save checkpoint (Îß§ epoch Ï†ÄÏû•) ----
        ckpt_name = f"epoch_{epoch_num:03d}_ssim{val_ssim:.4f}_psnr{val_psnr:.2f}.pth"
        ckpt_path = os.path.join(SAVE_DIR, ckpt_name)
        torch.save(model.state_dict(), ckpt_path)
        print(f"[Save] {ckpt_path}")


if __name__ == "__main__":
    main() """

# gopro
import os
import sys
import time
import re

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import transforms
from tqdm import tqdm

from torch.amp import autocast, GradScaler
import numpy as np
from skimage.metrics import peak_signal_noise_ratio as compute_psnr
from skimage.metrics import structural_similarity as compute_ssim

from PIL import Image, ImageDraw, ImageFont

# ----------------------
# Path setup (models: current dir, re_dataset: repo root)
# ----------------------
CUR_DIR = os.path.dirname(os.path.abspath(__file__))  # .../Restormer + Volterra
ROOT_DIR = os.path.dirname(CUR_DIR)                   # .../restormer+volterra
for p in [CUR_DIR, ROOT_DIR]:
    if p not in sys.path:
        sys.path.insert(0, p)

from models.restormer_volterra import RestormerVolterra
from re_dataset.gopro_dataset import GoProDataset


# ======================
# Config
# ======================
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ‚úÖ GoPro paths (CSV)
GOPRO_TRAIN_CSV = r"E:/restormer+volterra/data/GOPRO_Large/gopro_train_pairs.csv"
GOPRO_TEST_CSV  = r"E:/restormer+volterra/data/GOPRO_Large/gopro_test_pairs.csv"

SAVE_DIR = r"E:/restormer+volterra/checkpoints/restormer_volterra_gopro"
os.makedirs(SAVE_DIR, exist_ok=True)

RESULTS_DIR = r"E:/restormer+volterra/results/gopro_train"
os.makedirs(RESULTS_DIR, exist_ok=True)

# ‚úÖ Resume checkpoint (Ïó¨Í∏∞Î∂ÄÌÑ∞ Ïù¥Ïñ¥ÏÑú ÌïôÏäµ)
RESUME = False  # FalseÎ©¥ Ï≤òÏùåÎ∂ÄÌÑ∞ ÌïôÏäµ
RESUME_CKPT = ""
BATCH_SIZE = 1
EPOCHS = 100              # ÏµúÏ¢Ö Î™©Ìëú epoch
LR = 2e-4
NUM_WORKERS = 4
PIN_MEMORY = True

USE_AMP = True
SAVE_VIS_EVERY_EPOCH = 1
NUM_VIS_SAVE = 5

resize_schedule = {
    0: 128,
    30: 192,
    60: 256,
}


def parse_epoch_from_ckpt(path: str) -> int:
    """
    ckpt ÌååÏùºÎ™ÖÏóêÏÑú epoch Î≤àÌò∏ Ï∂îÏ∂ú:
    e.g., epoch_013_ssim0.9465_psnr27.63.pth -> 13
    Ïã§Ìå®ÌïòÎ©¥ 0 Î∞òÌôò
    """
    name = os.path.basename(path)
    m = re.search(r"epoch_(\d+)", name)
    return int(m.group(1)) if m else 0


def get_transform(epoch: int):
    size = 256
    for key in sorted(resize_schedule.keys()):
        if epoch >= key:
            size = resize_schedule[key]
    return transforms.Compose([
        transforms.Resize((size, size)),
        transforms.ToTensor(),
    ]), size


def tensor_to_hwc01(x: torch.Tensor) -> np.ndarray:
    if x.dim() == 4:
        x = x[0]
    x = x.detach().float().clamp(0, 1).cpu().numpy()
    x = np.transpose(x, (1, 2, 0))
    return x


def hwc01_to_pil(img: np.ndarray) -> Image.Image:
    img_u8 = (np.clip(img, 0, 1) * 255.0).astype(np.uint8)
    return Image.fromarray(img_u8, mode="RGB")


def render_triplet_with_text(blur_np, restored_np, gt_np, psnr, ssim,
                             title_left="Input(Blur)", title_mid="Restored", title_right="GT",
                             pad=12, text_h=54) -> Image.Image:
    blur_p = hwc01_to_pil(blur_np)
    res_p = hwc01_to_pil(restored_np)
    gt_p = hwc01_to_pil(gt_np)

    w, h = blur_p.size
    canvas_w = w * 3 + pad * 4
    canvas_h = h + text_h + pad * 3

    canvas = Image.new("RGB", (canvas_w, canvas_h), (255, 255, 255))
    draw = ImageDraw.Draw(canvas)

    try:
        font = ImageFont.truetype("arial.ttf", 18)
        font_b = ImageFont.truetype("arial.ttf", 20)
    except Exception:
        font = ImageFont.load_default()
        font_b = ImageFont.load_default()

    y_title = pad
    draw.text((pad + (w // 2) - 40, y_title), title_left, fill=(0, 0, 0), font=font_b)
    draw.text((pad * 2 + w + (w // 2) - 35, y_title), title_mid, fill=(0, 0, 0), font=font_b)
    draw.text((pad * 3 + w * 2 + (w // 2) - 10, y_title), title_right, fill=(0, 0, 0), font=font_b)

    y_img = pad * 2 + 18
    x1 = pad
    x2 = pad * 2 + w
    x3 = pad * 3 + w * 2

    canvas.paste(blur_p, (x1, y_img))
    canvas.paste(res_p, (x2, y_img))
    canvas.paste(gt_p, (x3, y_img))

    y_text = y_img + h + pad
    metric_text = f"PSNR: {psnr:.2f} dB    SSIM: {ssim:.4f}"
    draw.text((pad, y_text), metric_text, fill=(0, 0, 0), font=font_b)

    return canvas


def evaluate_one_epoch(model, loader, criterion, epoch: int,
                       save_visuals: bool = True, num_save: int = 5):
    model.eval()
    total_loss = 0.0
    total_psnr, total_ssim, count = 0.0, 0.0, 0

    saved = 0
    epoch_vis_dir = os.path.join(RESULTS_DIR, f"epoch_{epoch:03d}")
    if save_visuals:
        os.makedirs(epoch_vis_dir, exist_ok=True)

    with torch.no_grad():
        for _, (blur, gt) in enumerate(tqdm(loader, desc="Validating", leave=False), start=1):
            blur = blur.to(DEVICE, non_blocking=True)
            gt = gt.to(DEVICE, non_blocking=True)

            with autocast(device_type="cuda", enabled=(USE_AMP and DEVICE.type == "cuda")):
                out = model(blur)
                loss = criterion(out, gt)

            total_loss += float(loss.item())

            blur_np = tensor_to_hwc01(blur)
            out_np = tensor_to_hwc01(out)
            gt_np = tensor_to_hwc01(gt)

            psnr = compute_psnr(gt_np, out_np, data_range=1.0)
            ssim = compute_ssim(gt_np, out_np, channel_axis=2, data_range=1.0, win_size=7)

            total_psnr += psnr
            total_ssim += ssim
            count += 1

            if save_visuals and saved < num_save:
                vis = render_triplet_with_text(blur_np, out_np, gt_np, psnr, ssim)
                out_path = os.path.join(epoch_vis_dir, f"sample_{saved+1:02d}_psnr{psnr:.2f}_ssim{ssim:.4f}.png")
                vis.save(out_path)
                saved += 1

    avg_loss = total_loss / max(len(loader), 1)
    avg_psnr = total_psnr / max(count, 1)
    avg_ssim = total_ssim / max(count, 1)
    return avg_loss, avg_psnr, avg_ssim


def main():
    torch.backends.cudnn.benchmark = True
    if DEVICE.type == "cuda":
        torch.cuda.empty_cache()

    model = RestormerVolterra().to(DEVICE)
    criterion = nn.MSELoss()
    optimizer = optim.Adam(model.parameters(), lr=LR)
    scaler = GradScaler(device="cuda")

    # ----------------------
    # ‚úÖ Resume (model weights)
    # ----------------------
    start_epoch = 0  # 0-based index for loop
    if RESUME:
        if not os.path.exists(RESUME_CKPT):
            raise FileNotFoundError(f"Resume checkpoint not found: {RESUME_CKPT}")

        print(f"[Resume] Loading: {RESUME_CKPT}")
        state = torch.load(RESUME_CKPT, map_location=DEVICE)
        model.load_state_dict(state, strict=True)

        last_epoch = parse_epoch_from_ckpt(RESUME_CKPT)
        start_epoch = last_epoch
        print(f"[Resume] Detected last_epoch={last_epoch} -> start from epoch {start_epoch+1}")

    # ----------------------
    # Training loop
    # ----------------------
    for epoch_idx in range(start_epoch, EPOCHS):
        epoch_num = epoch_idx + 1

        transform, size = get_transform(epoch_num)

        # ‚úÖ GoPro dataset (CSV)
        train_set = GoProDataset(GOPRO_TRAIN_CSV, transform=transform)
        test_set  = GoProDataset(GOPRO_TEST_CSV,  transform=transform)

        train_loader = DataLoader(
            train_set,
            batch_size=BATCH_SIZE,
            shuffle=True,
            num_workers=NUM_WORKERS,
            pin_memory=(PIN_MEMORY and DEVICE.type == "cuda"),
            drop_last=True,
        )
        test_loader = DataLoader(
            test_set,
            batch_size=1,
            shuffle=False,
            num_workers=NUM_WORKERS,
            pin_memory=(PIN_MEMORY and DEVICE.type == "cuda"),
        )

        print(f"\n[Epoch {epoch_num}/{EPOCHS}] GoPro input: {size}x{size} | train={len(train_set)} | test={len(test_set)}")

        # ---- Train ----
        model.train()
        epoch_loss = 0.0
        total_psnr, total_ssim, count = 0.0, 0.0, 0

        loop = tqdm(train_loader, desc=f"Train [{epoch_num}/{EPOCHS}]", leave=False)
        t0 = time.time()

        for _, (blur, gt) in enumerate(loop, start=1):
            blur = blur.to(DEVICE, non_blocking=True)
            gt = gt.to(DEVICE, non_blocking=True)

            optimizer.zero_grad(set_to_none=True)

            with autocast(device_type="cuda", enabled=(USE_AMP and DEVICE.type == "cuda")):
                out = model(blur)
                loss = criterion(out, gt)

            scaler.scale(loss).backward()
            scaler.step(optimizer)
            scaler.update()

            epoch_loss += float(loss.item())

            out_np = tensor_to_hwc01(out)
            gt_np = tensor_to_hwc01(gt)

            psnr = compute_psnr(gt_np, out_np, data_range=1.0)
            ssim = compute_ssim(gt_np, out_np, channel_axis=2, data_range=1.0, win_size=7)

            total_psnr += psnr
            total_ssim += ssim
            count += 1

            loop.set_postfix(loss=f"{loss.item():.4f}", psnr=f"{psnr:.2f}", ssim=f"{ssim:.3f}")

        dt = time.time() - t0
        train_loss = epoch_loss / max(len(train_loader), 1)
        train_psnr = total_psnr / max(count, 1)
        train_ssim = total_ssim / max(count, 1)

        print(f"[Train] loss={train_loss:.6f} | psnr={train_psnr:.2f} | ssim={train_ssim:.4f} | time={dt/60:.1f}m")

        # ---- Validate + save visuals ----
        save_visuals = (SAVE_VIS_EVERY_EPOCH > 0) and (epoch_num % SAVE_VIS_EVERY_EPOCH == 0)
        val_loss, val_psnr, val_ssim = evaluate_one_epoch(
            model=model,
            loader=test_loader,
            criterion=criterion,
            epoch=epoch_num,
            save_visuals=save_visuals,
            num_save=NUM_VIS_SAVE
        )
        print(f"[Test ] loss={val_loss:.6f} | psnr={val_psnr:.2f} | ssim={val_ssim:.4f}")
        if save_visuals:
            print(f"[Vis  ] Saved {NUM_VIS_SAVE} triplets to: {os.path.join(RESULTS_DIR, f'epoch_{epoch_num:03d}')}")

        # ---- Save checkpoint (Îß§ epoch Ï†ÄÏû•) ----
        ckpt_name = f"epoch_{epoch_num:03d}_ssim{val_ssim:.4f}_psnr{val_psnr:.2f}.pth"
        ckpt_path = os.path.join(SAVE_DIR, ckpt_name)
        torch.save(model.state_dict(), ckpt_path)
        print(f"[Save] {ckpt_path}")


if __name__ == "__main__":
    main()
